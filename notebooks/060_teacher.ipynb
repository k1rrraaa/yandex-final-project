{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from timm import create_model\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from src.trainer import Trainer\n",
    "from src.dataset import HumanPosesDataset\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = \"browser\""
   ],
   "id": "6d161275fc8e945d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Датасет",
   "id": "63627c8f8f7e5998"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mean = [0.4638, 0.4522, 0.4148]\n",
    "std = [0.2222, 0.2198, 0.2176]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.5, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.TrivialAugmentWide(),\n",
    "    transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "    transforms.RandomErasing(p=0.25),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])"
   ],
   "id": "c7405db986e7e494",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "CSV_PATH = Path(\"../data/human_poses_data/train_answers.csv\")\n",
    "TRAIN_DIR = Path(\"../data/human_poses_data/img_train\")\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "train_ids, val_ids = train_test_split(\n",
    "    df['img_id'].values,\n",
    "    test_size=0.2,\n",
    "    stratify=df['target_feature'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_df = df[df['img_id'].isin(train_ids)].reset_index(drop=True)\n",
    "val_df = df[df['img_id'].isin(val_ids)].reset_index(drop=True)\n",
    "\n",
    "train_dataset = HumanPosesDataset(\n",
    "    data_df=train_df,\n",
    "    img_dir=TRAIN_DIR,\n",
    "    transform=train_transform,\n",
    ")\n",
    "\n",
    "val_dataset = HumanPosesDataset(\n",
    "    data_df=val_df,\n",
    "    img_dir=TRAIN_DIR,\n",
    "    transform=val_transform,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")"
   ],
   "id": "4c19c34a7d4f64bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_classes = len(np.unique(df['target_feature']))\n",
    "print(f\"Количество классов: {num_classes}\")"
   ],
   "id": "762ae478fb4e9015",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Модель",
   "id": "8af6879644ea4ba6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.models.teacher import ConvNeXtTeacher\n",
    "\n",
    "model = ConvNeXtTeacher(num_classes=num_classes)"
   ],
   "id": "9e9c04121f1a5985",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "model = ConvNeXtTeacher(num_classes=16).cuda()\n",
    "model.eval()\n",
    "\n",
    "dummy = torch.randn(4, 3, 224, 224).cuda()\n",
    "scaler = GradScaler()\n",
    "\n",
    "with autocast(device_type='cuda'):\n",
    "    with torch.no_grad():\n",
    "        out = model(dummy)\n",
    "print(\"Output shape:\", out.shape)  # [4, 16]"
   ],
   "id": "3c18e841f59fcf03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Голова",
   "id": "e055fb4ed99a0ec8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "NUM_EPOCH = 10\n",
    "\n",
    "model = ConvNeXtTeacher(num_classes=16).cuda()\n",
    "model.backbone.requires_grad_(False)\n",
    "model.train()\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.head.parameters(),\n",
    "    lr=3e-4,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=NUM_EPOCH\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "scaler = GradScaler()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"✅ Using device: {device}\")"
   ],
   "id": "f912e67477ae18fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=NUM_EPOCH,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scheduler=scheduler,\n",
    "    batch_augment_fn=None,\n",
    "    experiment_name=\"teacher\",\n",
    "    use_wandb=True,\n",
    "    seed=42,\n",
    "    scaler=scaler,\n",
    ")\n",
    "\n",
    "history = trainer.train()"
   ],
   "id": "74914bc26bd6e8c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Фулл",
   "id": "9a30b13ac0b86bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.utils import load_best_model\n",
    "from src.models.teacher import ConvNeXtTeacher\n",
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "NUM_EPOCH = 50\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"✅ Using device: {device}\")\n",
    "\n",
    "model = ConvNeXtTeacher(num_classes=16).cuda()\n",
    "model = load_best_model(model, 'checkpoints/teacher_best.pth', device=device)\n",
    "\n",
    "model.backbone.requires_grad_(True)\n",
    "model.train()\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=3e-4,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=3e-4,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    epochs=NUM_EPOCH,\n",
    "    pct_start=0.1,\n",
    "    anneal_strategy='cos',\n",
    "    div_factor=10.0,\n",
    "    final_div_factor=1e3\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "scaler = GradScaler()"
   ],
   "id": "f352c671de048cd5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.utils import MixupCutMixAugmenter\n",
    "\n",
    "mixup_cutmix_fn = MixupCutMixAugmenter(alpha=1.0, p_mixup=0.3)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=NUM_EPOCH,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scheduler=scheduler,\n",
    "    batch_augment_fn=mixup_cutmix_fn,\n",
    "    experiment_name=\"teacher_full\",\n",
    "    use_wandb=True,\n",
    "    seed=42,\n",
    "    scaler=scaler,\n",
    ")\n",
    "\n",
    "history = trainer.train()"
   ],
   "id": "4e0022f380cf2868",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "там какой то  потолок, я перезапущу модель и попробую понять какие классы она путает",
   "id": "3650066df51c73b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.utils import evaluate_model, load_best_model\n",
    "from src.models.teacher import ConvNeXtTeacher\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"✅ Using device: {device}\")\n",
    "\n",
    "model = ConvNeXtTeacher(num_classes=16).cuda()\n",
    "load_best_model(model, 'checkpoints/teacher_full_best.pth', device=device)\n",
    "\n",
    "evaluate_model(model, val_loader, device=device)"
   ],
   "id": "ca7631951a0c83d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "финальное дообучение до 0.9 ф1",
   "id": "26e49e2f6c0d5086"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.utils import load_best_model\n",
    "from src.models.teacher import ConvNeXtTeacher\n",
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "NUM_EPOCH = 25\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"✅ Using device: {device}\")\n",
    "\n",
    "model = ConvNeXtTeacher(num_classes=16).cuda()\n",
    "model = load_best_model(model, 'checkpoints/teacher_full_best.pth', device=device)\n",
    "\n",
    "model.backbone.requires_grad_(True)\n",
    "model.train()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=1e-4)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCH)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "scaler = GradScaler()"
   ],
   "id": "fa79f6d9ac42adb7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.utils import MixupCutMixAugmenter\n",
    "\n",
    "mixup_cutmix_fn = MixupCutMixAugmenter(alpha=1.0, p_mixup=0.3)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=NUM_EPOCH,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scheduler=scheduler,\n",
    "    batch_augment_fn=mixup_cutmix_fn,\n",
    "    experiment_name=\"teacher_full_finalmaybe\",\n",
    "    use_wandb=True,\n",
    "    seed=42,\n",
    "    scaler=scaler,\n",
    ")\n",
    "\n",
    "history = trainer.train()"
   ],
   "id": "4a14201dc5c01e79",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Сабмит",
   "id": "3b123d47edbf2536"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "TEST_DIR = Path(\"../data/human_poses_data/img_test\")\n",
    "\n",
    "test_ids = [f.stem for f in TEST_DIR.glob(\"*.jpg\")]\n",
    "test_df = pd.DataFrame({\"img_id\": test_ids})\n",
    "\n",
    "\n",
    "test_dataset = HumanPosesDataset(\n",
    "    data_df=test_df,\n",
    "    img_dir=TEST_DIR,\n",
    "    transform=val_transform,\n",
    "    preload=False,\n",
    "    mode='test',\n",
    ")\n",
    "\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n"
   ],
   "id": "b7f062b7a727dcb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"✅ Using device: {device}\")"
   ],
   "id": "fa3a92cdad3fd39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.models.teacher import ConvNeXtTeacher\n",
    "from src.utils import load_best_model, make_submission\n",
    "\n",
    "index_to_class = train_dataset.index_to_class\n",
    "\n",
    "model = ConvNeXtTeacher(num_classes=num_classes)\n",
    "\n",
    "load_best_model(model, 'checkpoints/teacher_full_finalmaybe_best.pth', device=device)\n",
    "\n",
    "make_submission(model, test_loader, device=device, index_to_class=index_to_class)"
   ],
   "id": "24aa1c08258aedd9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "(это чтобы скрыть свои скоры от других(ну там другие команды также сделали), отправлять эту модель в приватный лидерборд я не буду)",
   "id": "386b7961e0704af6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!kaggle competitions submit -c ml-intensive-yandex-academy-spring-2025 -f submission.csv -m \"Message\"",
   "id": "2c05ae75b1b3a252",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
