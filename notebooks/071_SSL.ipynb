{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from src.trainer import Trainer\n",
    "from src.dataset import HumanPosesDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch"
   ],
   "id": "fdf7ffc785300906",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = \"browser\""
   ],
   "id": "499ae04dbee96a00",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# fjsaodifjodsf",
   "id": "b81b5b266986d0a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "mean = [0.4638, 0.4522, 0.4148]\n",
    "std = [0.2222, 0.2198, 0.2176]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.5, 1.0), ratio=(0.75, 1.33)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandAugment(num_ops=2, magnitude=9),\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std),\n",
    "    transforms.RandomErasing(p=0.25, scale=(0.02, 0.2), ratio=(0.3, 3.3), value='random')\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std),\n",
    "])"
   ],
   "id": "82513e034c7f9fcd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "CSV_PATH = Path(\"../data/human_poses_data/train_answers.csv\")\n",
    "TRAIN_DIR = Path(\"../data/human_poses_data/img_train\")\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "train_ids, val_ids = train_test_split(\n",
    "    df['img_id'].values,\n",
    "    test_size=0.2,\n",
    "    stratify=df['target_feature'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_df = df[df['img_id'].isin(train_ids)].reset_index(drop=True)\n",
    "val_df = df[df['img_id'].isin(val_ids)].reset_index(drop=True)\n",
    "\n",
    "train_dataset = HumanPosesDataset(\n",
    "    data_df=train_df,\n",
    "    img_dir=TRAIN_DIR,\n",
    "    transform=train_transform,\n",
    ")\n",
    "\n",
    "val_dataset = HumanPosesDataset(\n",
    "    data_df=val_df,\n",
    "    img_dir=TRAIN_DIR,\n",
    "    transform=val_transform,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")"
   ],
   "id": "9e5817bef972824f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_classes = len(np.unique(df['target_feature']))\n",
    "print(f\"Количество классов: {num_classes}\")"
   ],
   "id": "7e180933b3794a7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# fdosjkfopisdf",
   "id": "98a9e27839cb55b1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"✅ Using device: {device}\")"
   ],
   "id": "7e6c93bb253fc7ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from src.models.tinyvit import TinyViT\n",
    "from torch import nn\n",
    "\n",
    "base_model = TinyViT(in_chans=3, num_classes=num_classes, model_size='11M')\n",
    "\n",
    "class TinyViTEncoder(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super().__init__()\n",
    "        self.patch_embed = base_model.patch_embed\n",
    "        self.stages = base_model.stages\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        for stage in self.stages:\n",
    "            x = stage(x)\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def patchify(imgs, patch_size):\n",
    "    B, C, H, W = imgs.shape\n",
    "    h = w = H // patch_size\n",
    "    patches = imgs.reshape(B, C, h, patch_size, w, patch_size)\n",
    "    patches = patches.permute(0, 2, 4, 3, 5, 1).reshape(B, h * w, patch_size * patch_size * C)\n",
    "    return patches\n",
    "\n",
    "def unpatchify(patches, patch_size, img_size):\n",
    "    B, N, D = patches.shape\n",
    "    h = w = img_size // patch_size\n",
    "    patches = patches.reshape(B, h, w, patch_size, patch_size, 3)\n",
    "    patches = patches.permute(0, 5, 1, 3, 2, 4)\n",
    "    imgs = patches.reshape(B, 3, img_size, img_size)\n",
    "    return imgs"
   ],
   "id": "7d58dac2fc364d6b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class MAEWrapper(nn.Module):\n",
    "    def __init__(self, encoder: nn.Module, encoder_dim: int,\n",
    "                 img_size=224, patch_size=16,\n",
    "                 decoder_dim=512, decoder_depth=4, mask_ratio=0.75):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.mask_ratio = mask_ratio\n",
    "        self.patch_size = patch_size\n",
    "        self.img_size = img_size\n",
    "        self.num_patches = (img_size // patch_size) ** 2\n",
    "\n",
    "        self.mask_token = nn.Parameter(torch.zeros(1, 1, decoder_dim))\n",
    "        self.decoder_pos_embed = nn.Parameter(torch.randn(1, self.num_patches, decoder_dim))\n",
    "\n",
    "        self.encoder_to_decoder = nn.Linear(encoder_dim, decoder_dim, bias=False)\n",
    "\n",
    "        self.decoder_blocks = nn.Sequential(*[\n",
    "            nn.TransformerEncoderLayer(d_model=decoder_dim, nhead=8, dim_feedforward=2048, dropout=0.1, activation='gelu')\n",
    "            for _ in range(decoder_depth)\n",
    "        ])\n",
    "\n",
    "        self.decoder_pred = nn.Linear(decoder_dim, patch_size * patch_size * 3)\n",
    "\n",
    "    def forward(self, imgs):\n",
    "        patches = patchify(imgs, self.patch_size)\n",
    "        B, N, D = patches.shape\n",
    "\n",
    "        len_keep = int(N * (1 - self.mask_ratio))\n",
    "        noise = torch.rand(B, N, device=imgs.device)\n",
    "        ids_shuffle = torch.argsort(noise, dim=1)\n",
    "        ids_restore = torch.argsort(ids_shuffle, dim=1)\n",
    "        ids_keep = ids_shuffle[:, :len_keep]\n",
    "\n",
    "\n",
    "\n",
    "        feats = self.encoder(imgs)\n",
    "        B, C, H, W = feats.shape\n",
    "        x = feats.flatten(2).transpose(1, 2)\n",
    "\n",
    "        x = self.encoder_to_decoder(x)\n",
    "\n",
    "        mask_tokens = self.mask_token.repeat(B, N - len_keep, 1)\n",
    "        x_full = torch.cat([x, mask_tokens], dim=1)\n",
    "        x_full = torch.gather(x_full, dim=1, index=ids_restore.unsqueeze(-1).repeat(1, 1, x.shape[-1]))\n",
    "        x_full = x_full + self.decoder_pos_embed\n",
    "\n",
    "        x_dec = self.decoder_blocks(x_full)\n",
    "        pred = self.decoder_pred(x_dec)\n",
    "\n",
    "        target = patches\n",
    "        mask = torch.ones([B, N], device=imgs.device)\n",
    "        mask.scatter_(1, ids_keep, 0)\n",
    "        loss = ((pred - target) ** 2 * mask.unsqueeze(-1)).sum() / mask.sum()\n",
    "\n",
    "        return loss, pred, mask"
   ],
   "id": "ac738efe1e15615c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.amp import autocast, GradScaler\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_mae_epoch(model, dataloader, optimizer, scheduler=None, scaler=None,\n",
    "                    device=\"cuda\", patch_size=16, max_norm=1.0, desc=\"MAE Train Epoch\"):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    pbar = tqdm(dataloader, desc=desc)\n",
    "\n",
    "    for imgs in pbar:\n",
    "        imgs = imgs.to(device)\n",
    "\n",
    "        targets = patchify(imgs, patch_size).to(device)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with autocast(enabled=scaler is not None, device_type='cuda'):\n",
    "            _, preds, _ = model(imgs)\n",
    "            loss = torch.nn.functional.mse_loss(preds, targets)\n",
    "\n",
    "        if scaler:\n",
    "            scaler.scale(loss).backward()\n",
    "            if max_norm is not None:\n",
    "                scaler.unscale_(optimizer)\n",
    "                clip_grad_norm_(model.parameters(), max_norm)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            if max_norm is not None:\n",
    "                clip_grad_norm_(model.parameters(), max_norm)\n",
    "            optimizer.step()\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({\"loss\": loss.item()})\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss"
   ],
   "id": "bd8c0fad204b16a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from src.mae_dataset import MAEDataset\n",
    "\n",
    "dataset = MAEDataset(\"../data/human_poses_data/img_train/\", img_size=224)\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=4)"
   ],
   "id": "d4f8fd7a41df7ac7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "base = TinyViT(model_size='11M')\n",
    "encoder = TinyViTEncoder(base)\n",
    "mae = MAEWrapper(encoder, encoder_dim=448).cuda()"
   ],
   "id": "ecd740783025fb1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.amp import GradScaler\n",
    "\n",
    "NUM_EPOCH = 50\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = AdamW(mae.parameters(), lr=3e-4, weight_decay=1e-3)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=NUM_EPOCH,\n",
    "    eta_min=1e-6\n",
    ")\n",
    "\n",
    "scaler = GradScaler()"
   ],
   "id": "61cea9c81c515432",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for epoch in range(NUM_EPOCH):\n",
    "    avg_loss = train_mae_epoch(\n",
    "        model=mae,\n",
    "        dataloader=loader,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        scaler=scaler,\n",
    "        device=\"cuda\",\n",
    "        patch_size=16,\n",
    "        max_norm=1.0,\n",
    "        desc=f\"Epoch {epoch+1}\"\n",
    "    )\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}] Loss: {avg_loss:.4f}\")\n",
    "    torch.save(encoder.state_dict(), f\"mae_encoder_epoch{epoch+1}.pth\")\n"
   ],
   "id": "6069c84c4d2fff6d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# мовымщоывща",
   "id": "96d35ab6103bf708"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = TinyViT(model_size=\"11M\", num_classes=16)\n",
    "model.load_state_dict(torch.load(\"mae_encoder_epoch50.pth\"), strict=False)"
   ],
   "id": "ab64478bafb92faa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for param in model.patch_embed.parameters():\n",
    "    param.requires_grad = False\n",
    "for stage in model.stages:\n",
    "    for param in stage.parameters():\n",
    "        param.requires_grad = False"
   ],
   "id": "4af8c9d81861352b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.amp import GradScaler\n",
    "\n",
    "NUM_EPOCH = 10\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=3e-4, weight_decay=1e-3)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, T_max=NUM_EPOCH, eta_min=1e-6\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "scaler = GradScaler()"
   ],
   "id": "2ca1f31cd2a6033a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.utils import MixupCutMixAugmenter\n",
    "\n",
    "mixup_cutmix_fn = MixupCutMixAugmenter(alpha=1.0, p_mixup=0.5)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=NUM_EPOCH,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scheduler=scheduler,\n",
    "    batch_augment_fn=mixup_cutmix_fn,\n",
    "    experiment_name=\"ssl_vit_1_1\",\n",
    "    use_wandb=True,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "history = trainer.train()"
   ],
   "id": "8e767b1e1e762b3b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.utils import load_best_model\n",
    "\n",
    "load_best_model(model, 'checkpoints/ssl_vit_1_1_best.pth', device)"
   ],
   "id": "2a3001785666fc4d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ],
   "id": "bb564303c6246eb2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.amp import GradScaler\n",
    "\n",
    "NUM_EPOCH = 50\n",
    "\n",
    "head_params = list(model.head.parameters()) + list(model.norm_head.parameters())\n",
    "encoder_params = [p for n, p in model.named_parameters() if (\"head\" not in n and \"norm_head\" not in n)]\n",
    "\n",
    "optimizer = AdamW([\n",
    "    {'params': encoder_params, 'lr': 3e-4},\n",
    "    {'params': head_params, 'lr': 3e-3}\n",
    "], weight_decay=1e-3)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=[3e-4, 3e-3],\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    epochs=NUM_EPOCH,\n",
    "    pct_start=0.1,\n",
    "    anneal_strategy='cos',\n",
    "    div_factor=10.0,\n",
    "    final_div_factor=500\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "scaler = GradScaler()"
   ],
   "id": "c6f8ab6fa94f280e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.utils import MixupCutMixAugmenter\n",
    "\n",
    "mixup_cutmix_fn = MixupCutMixAugmenter(alpha=1.0, p_mixup=0.5)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=NUM_EPOCH,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scheduler=scheduler,\n",
    "    batch_augment_fn=mixup_cutmix_fn,\n",
    "    experiment_name=\"ssl_vit_1_2\",\n",
    "    use_wandb=True,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "history = trainer.train()"
   ],
   "id": "60337dfed27b5fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "load_best_model(model, 'checkpoints/ssl_vit_1_2_best.pth', device)",
   "id": "3e876b1a3d5ade31",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "NUM_EPOCH = 100\n",
    "\n",
    "head_params = list(model.head.parameters()) + list(model.norm_head.parameters())\n",
    "encoder_params = [p for n, p in model.named_parameters() if (\"head\" not in n and \"norm_head\" not in n)]\n",
    "\n",
    "optimizer = AdamW([\n",
    "    {'params': encoder_params, 'lr': 1e-4},\n",
    "    {'params': head_params, 'lr': 3e-4}\n",
    "], weight_decay=1e-3)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=NUM_EPOCH,\n",
    "    eta_min=1e-6\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "scaler = GradScaler()"
   ],
   "id": "be2dac62d996cb60",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.utils import MixupCutMixAugmenter\n",
    "\n",
    "mixup_cutmix_fn = MixupCutMixAugmenter(alpha=0.75, p_mixup=0.5)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=NUM_EPOCH,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scheduler=scheduler,\n",
    "    batch_augment_fn=mixup_cutmix_fn,\n",
    "    experiment_name=\"ssl_vit_1_2\",\n",
    "    use_wandb=True,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "history = trainer.train()"
   ],
   "id": "c4dca408e8c82b08",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.utils import load_best_model\n",
    "\n",
    "load_best_model(model, 'checkpoints/ssl_vit_1_2_best.pth', device)"
   ],
   "id": "e33330c29044ad01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.amp import GradScaler\n",
    "\n",
    "NUM_EPOCH = 75\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=NUM_EPOCH,\n",
    "    eta_min=1e-7\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "scaler = GradScaler()"
   ],
   "id": "cd701e1a7b7fe4a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.utils import MixupCutMixAugmenter\n",
    "\n",
    "mixup_cutmix_fn = MixupCutMixAugmenter(alpha=0.5, p_mixup=0.5)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=NUM_EPOCH,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scheduler=scheduler,\n",
    "    batch_augment_fn=mixup_cutmix_fn,\n",
    "    experiment_name=\"ssl_vit_1_3\",\n",
    "    use_wandb=True,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "history = trainer.train()"
   ],
   "id": "f00add0a33e0309f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.utils import load_best_model\n",
    "\n",
    "load_best_model(model, 'checkpoints/ssl_vit_1_3_best.pth', device)"
   ],
   "id": "a6199dcabd7d941e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.amp import GradScaler\n",
    "\n",
    "NUM_EPOCH = 75\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=NUM_EPOCH,\n",
    "    eta_min=1e-7\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "scaler = GradScaler()"
   ],
   "id": "5b362cd1ef9caa9f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.utils import MixupCutMixAugmenter\n",
    "\n",
    "mixup_cutmix_fn = MixupCutMixAugmenter(alpha=0.25, p_mixup=0.5)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=NUM_EPOCH,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scheduler=scheduler,\n",
    "    batch_augment_fn=mixup_cutmix_fn,\n",
    "    experiment_name=\"ssl_vit_1_4\",\n",
    "    use_wandb=True,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "history = trainer.train()"
   ],
   "id": "832713f02dfc8036",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "load_best_model(model, 'checkpoints/ssl_vit_1_4_best.pth', device)",
   "id": "47665af03f3360ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.test_dataset_for_tta import TestDataset, make_submission_with_tta\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "TEST_DIR = Path(\"../data/human_poses_data/img_test\")\n",
    "\n",
    "def pil_collate(batch):\n",
    "    images, ids = zip(*batch)\n",
    "    return list(images), list(ids)\n",
    "\n",
    "\n",
    "test_image_paths = list(TEST_DIR.glob(\"*.jpg\"))\n",
    "test_ids = [int(p.stem) for p in test_image_paths]\n",
    "\n",
    "test_dataset = TestDataset(test_image_paths, test_ids)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=pil_collate,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "make_submission_with_tta(model, test_loader, device, train_dataset.index_to_class)"
   ],
   "id": "874b9913567bbf7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!kaggle competitions submit -c ml-intensive-yandex-academy-spring-2025 -f submission.csv -m \"Message\"",
   "id": "9fc8e4c537593b0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.utils import load_best_model\n",
    "\n",
    "load_best_model(model, 'checkpoints/ssl_vit_1_4_best.pth', device)"
   ],
   "id": "a6cc3de9fbcd8a99",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.amp import GradScaler\n",
    "\n",
    "NUM_EPOCH = 75\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=NUM_EPOCH,\n",
    "    eta_min=1e-7\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "scaler = GradScaler()"
   ],
   "id": "cd3f84458b07e246",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.utils import MixupCutMixAugmenter\n",
    "\n",
    "mixup_cutmix_fn = MixupCutMixAugmenter(alpha=0.25, p_mixup=0.5)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=NUM_EPOCH,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scheduler=scheduler,\n",
    "    batch_augment_fn=mixup_cutmix_fn,\n",
    "    experiment_name=\"ssl_vit_1_5\",\n",
    "    use_wandb=True,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "history = trainer.train()"
   ],
   "id": "8306870695c88db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "load_best_model(model, 'checkpoints/ssl_vit_1_5_best.pth', device)",
   "id": "a9a1801a412ca10a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.test_dataset_for_tta import TestDataset, make_submission_with_tta\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "TEST_DIR = Path(\"../data/human_poses_data/img_test\")\n",
    "\n",
    "def pil_collate(batch):\n",
    "    images, ids = zip(*batch)\n",
    "    return list(images), list(ids)\n",
    "\n",
    "\n",
    "test_image_paths = list(TEST_DIR.glob(\"*.jpg\"))\n",
    "test_ids = [int(p.stem) for p in test_image_paths]\n",
    "\n",
    "test_dataset = TestDataset(test_image_paths, test_ids)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=pil_collate,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "make_submission_with_tta(model, test_loader, device, train_dataset.index_to_class)"
   ],
   "id": "b77c558bfb370cef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!kaggle competitions submit -c ml-intensive-yandex-academy-spring-2025 -f submission.csv -m \"Message\"",
   "id": "351e8f1b13b2fe01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "adbea5d166f2828d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
