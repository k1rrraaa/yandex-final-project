{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T13:27:15.924388Z",
     "start_time": "2025-04-12T13:27:07.311387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from src.dataset import HumanPosesDataset\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "id": "1120ddcca59029de",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T13:27:16.036476Z",
     "start_time": "2025-04-12T13:27:15.931658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = \"browser\""
   ],
   "id": "f93d2b0985b9fe1c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Датасет",
   "id": "907c346b5ad4f806"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T13:27:17.692582Z",
     "start_time": "2025-04-12T13:27:16.329570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.5, 1.0), ratio=(0.75, 1.33)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
    "    transforms.RandomApply([\n",
    "        transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0))\n",
    "    ], p=0.3),\n",
    "    transforms.RandomApply([\n",
    "        transforms.RandomAffine(degrees=15, translate=(0.05, 0.05), scale=(0.9, 1.1))\n",
    "    ], p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(p=0.25, scale=(0.02, 0.2), ratio=(0.3, 3.3), value='random'),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n"
   ],
   "id": "4ab6bb4cf3bc6cef",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T13:27:17.738843Z",
     "start_time": "2025-04-12T13:27:17.720222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CSV_PATH = Path(\"../data/human_poses_data/train_answers.csv\")\n",
    "TRAIN_DIR = Path(\"../data/human_poses_data/img_train\")\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "train_ids, val_ids = train_test_split(\n",
    "    df['img_id'].values,\n",
    "    test_size=0.2,\n",
    "    stratify=df['target_feature'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_df = df[df['img_id'].isin(train_ids)].reset_index(drop=True)\n",
    "val_df = df[df['img_id'].isin(val_ids)].reset_index(drop=True)\n",
    "\n",
    "train_dataset = HumanPosesDataset(\n",
    "    data_df=train_df,\n",
    "    img_dir=TRAIN_DIR,\n",
    "    transform=train_transform,\n",
    ")\n",
    "\n",
    "val_dataset = HumanPosesDataset(\n",
    "    data_df=val_df,\n",
    "    img_dir=TRAIN_DIR,\n",
    "    transform=val_transform,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")"
   ],
   "id": "66be7fe32d4512fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 9893\n",
      "Validation dataset size: 2474\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T13:27:17.750921Z",
     "start_time": "2025-04-12T13:27:17.747874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_classes = len(np.unique(df['target_feature']))\n",
    "print(f\"Количество классов: {num_classes}\")"
   ],
   "id": "cfe8c940f069aba1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество классов: 16\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Переписанные функции обучения",
   "id": "9cd05968f4b9a586"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T13:27:17.778093Z",
     "start_time": "2025-04-12T13:27:17.768764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def cross_entropy_with_smoothing(logits, targets, smoothing=0.0):\n",
    "    confidence = 1.0 - smoothing\n",
    "    log_probs = F.log_softmax(logits, dim=-1)\n",
    "    n_classes = logits.size(-1)\n",
    "\n",
    "    true_dist = torch.zeros_like(log_probs)\n",
    "    true_dist.fill_(smoothing / (n_classes - 1))\n",
    "    true_dist.scatter_(1, targets.unsqueeze(1), confidence)\n",
    "\n",
    "    return F.cross_entropy(logits, targets, label_smoothing=smoothing, reduction='none')\n",
    "\n",
    "\n",
    "\n",
    "class DistillationLoss(nn.Module):\n",
    "    def __init__(self, teacher_model, temperature=4.0, alpha=0.7, ce_smoothing=0.1):\n",
    "        super().__init__()\n",
    "        self.teacher = teacher_model.eval()\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "        self.ce_smoothing = ce_smoothing\n",
    "\n",
    "    def forward(self, student_logits, _, labels):\n",
    "        if not (isinstance(labels, tuple) and len(labels) == 2):\n",
    "            raise ValueError(\"Expected labels to be ((targets or (y_a, y_b, lam)), x_teacher)\")\n",
    "\n",
    "        inner_labels, x_teacher = labels\n",
    "        x_teacher = x_teacher.to(student_logits.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            teacher_logits = self.teacher(x_teacher)\n",
    "\n",
    "        T = self.temperature\n",
    "        soft_teacher = F.softmax(teacher_logits / T, dim=1)\n",
    "        soft_student = F.log_softmax(student_logits / T, dim=1)\n",
    "        distill_loss = F.kl_div(soft_student, soft_teacher, reduction='batchmean') * (T ** 2)\n",
    "\n",
    "\n",
    "        if isinstance(inner_labels, tuple) and len(inner_labels) == 3:\n",
    "            y_a, y_b, lam = inner_labels\n",
    "            y_a = y_a.to(student_logits.device)\n",
    "            y_b = y_b.to(student_logits.device)\n",
    "\n",
    "            ce_loss_a = cross_entropy_with_smoothing(student_logits, y_a, self.ce_smoothing)\n",
    "            ce_loss_b = cross_entropy_with_smoothing(student_logits, y_b, self.ce_smoothing)\n",
    "            ce_loss = lam * ce_loss_a + (1 - lam) * ce_loss_b\n",
    "            ce_loss = ce_loss.mean()\n",
    "\n",
    "            labels_for_f1 = y_a\n",
    "        else:\n",
    "            targets = inner_labels.to(student_logits.device)\n",
    "            ce_loss = cross_entropy_with_smoothing(student_logits, targets, self.ce_smoothing)\n",
    "            ce_loss = ce_loss.mean()\n",
    "            labels_for_f1 = targets\n",
    "\n",
    "        total_loss = self.alpha * distill_loss + (1 - self.alpha) * ce_loss\n",
    "        return total_loss, labels_for_f1\n",
    "\n",
    "def distill_batch_augment(images, labels, teacher_transform):\n",
    "    to_pil = transforms.ToPILImage()\n",
    "    x_teacher = torch.stack([\n",
    "        teacher_transform(to_pil(img.cpu())).to(images.device)\n",
    "        for img in images\n",
    "    ])\n",
    "\n",
    "    return images, (labels, x_teacher)\n",
    "\n",
    "\n",
    "class MixupCutMixAugmenter:\n",
    "    def __init__(self, alpha=1.0, p_mixup=0.5, p=1.0):\n",
    "        self.alpha = alpha\n",
    "        self.p_mixup = p_mixup\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        if random.random() > self.p:\n",
    "            return x, y\n",
    "\n",
    "        y = y.to(x.device)\n",
    "        if random.random() < self.p_mixup:\n",
    "            return self.mixup(x, y)\n",
    "        else:\n",
    "            return self.cutmix(x, y)\n",
    "\n",
    "\n",
    "    def mixup(self, x, y):\n",
    "        lam = np.random.beta(self.alpha, self.alpha)\n",
    "        batch_size = x.size(0)\n",
    "        index = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "        mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "        y_a, y_b = y, y[index]\n",
    "        return mixed_x, (y_a, y_b, lam)\n",
    "\n",
    "    def cutmix(self, x, y):\n",
    "        lam = np.random.beta(self.alpha, self.alpha)\n",
    "        batch_size, _, height, width = x.size()\n",
    "        index = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "        cut_rat = np.sqrt(1. - lam)\n",
    "        cut_w = int(width * cut_rat)\n",
    "        cut_h = int(height * cut_rat)\n",
    "\n",
    "        cx = random.randint(0, width)\n",
    "        cy = random.randint(0, height)\n",
    "\n",
    "        bbx1 = np.clip(cx - cut_w // 2, 0, width)\n",
    "        bby1 = np.clip(cy - cut_h // 2, 0, height)\n",
    "        bbx2 = np.clip(cx + cut_w // 2, 0, width)\n",
    "        bby2 = np.clip(cy + cut_h // 2, 0, height)\n",
    "\n",
    "        x[:, :, bby1:bby2, bbx1:bbx2] = x[index, :, bby1:bby2, bbx1:bbx2]\n",
    "        y_a, y_b = y, y[index]\n",
    "        return x, (y_a, y_b, lam)\n",
    "\n",
    "def distill_mixupcutmix_augment(mixcut_fn, teacher_transform):\n",
    "    def wrapper(images, labels):\n",
    "        images, labels = mixcut_fn(images, labels)\n",
    "        to_pil = transforms.ToPILImage()\n",
    "        x_teacher = torch.stack([\n",
    "            teacher_transform(to_pil(img.cpu())).to(images.device)\n",
    "            for img in images\n",
    "        ])\n",
    "        return images, (labels, x_teacher)\n",
    "    return wrapper\n"
   ],
   "id": "9d4c5eaa82d34ba9",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T13:27:17.803336Z",
     "start_time": "2025-04-12T13:27:17.795648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "from torch.amp import autocast\n",
    "from torchvision import transforms\n",
    "\n",
    "def training_epoch(model, optimizer, criterion, train_loader, device, tqdm_desc, batch_augment_fn=None, scheduler=None, scaler=None):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    is_onecycle = isinstance(scheduler, torch.optim.lr_scheduler.OneCycleLR)\n",
    "\n",
    "    step_scheduler_per_batch = isinstance(scheduler, OneCycleLR)\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=tqdm_desc):\n",
    "        images = images.to(device)\n",
    "\n",
    "        if batch_augment_fn is not None:\n",
    "            images, labels = batch_augment_fn(images, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if scaler is not None:\n",
    "            with autocast(device_type='cuda'):\n",
    "                logits = model(images)\n",
    "                if isinstance(criterion, DistillationLoss):\n",
    "                    loss, labels_for_f1 = criterion(logits, None, labels)\n",
    "                else:\n",
    "                    if isinstance(labels, tuple) and len(labels) == 3:\n",
    "                        y_a, y_b, lam = labels\n",
    "                        loss = lam * criterion(logits, y_a) + (1 - lam) * criterion(logits, y_b)\n",
    "                        labels_for_f1 = y_a\n",
    "                    else:\n",
    "                        loss = criterion(logits, labels)\n",
    "                        labels_for_f1 = labels\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            if is_onecycle and scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "\n",
    "        else:\n",
    "            logits = model(images)\n",
    "            if isinstance(criterion, DistillationLoss):\n",
    "                loss, labels_for_f1 = criterion(logits, None, labels)\n",
    "            else:\n",
    "                if isinstance(labels, tuple) and len(labels) == 3:\n",
    "                    y_a, y_b, lam = labels\n",
    "                    loss = lam * criterion(logits, y_a) + (1 - lam) * criterion(logits, y_b)\n",
    "                    labels_for_f1 = y_a\n",
    "                else:\n",
    "                    loss = criterion(logits, labels)\n",
    "                    labels_for_f1 = labels\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            if scheduler is not None and step_scheduler_per_batch:\n",
    "                scheduler.step()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        all_preds.append(logits.detach().argmax(dim=1).cpu())\n",
    "        all_labels.append(labels_for_f1.cpu())\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_f1 = f1_score(torch.cat(all_labels), torch.cat(all_preds), average='macro')\n",
    "    return train_loss, train_f1\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validation_epoch(model, criterion, val_loader, device, tqdm_desc, teacher_model=None, teacher_transform=None):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    to_pil = transforms.ToPILImage()\n",
    "\n",
    "    for images, labels in tqdm(val_loader, desc=tqdm_desc):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        if isinstance(criterion, DistillationLoss):\n",
    "            x_teacher = torch.stack([\n",
    "                val_transform(to_pil(img.cpu())).to(device)\n",
    "                for img in images\n",
    "            ])\n",
    "            logits = model(images)\n",
    "            loss, _ = criterion(logits, None, (labels, x_teacher))\n",
    "        else:\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "        val_loss += loss.item() * images.size(0)\n",
    "        all_preds.append(logits.argmax(dim=1).cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_f1 = f1_score(torch.cat(all_labels), torch.cat(all_preds), average='macro')\n",
    "    return val_loss, val_f1\n"
   ],
   "id": "f905e45a8e35b31e",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T13:27:19.729156Z",
     "start_time": "2025-04-12T13:27:17.806844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "import wandb\n",
    "from src.utils import set_seed, plot_losses\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        num_epochs: int,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        scheduler=None,\n",
    "        device: str = 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "        experiment_name: str = 'experiment',\n",
    "        save_dir: str = 'checkpoints',\n",
    "        use_wandb: bool = False,\n",
    "        seed: int = 42,\n",
    "        batch_augment_fn=None,\n",
    "        scaler=None,\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.num_epochs = num_epochs\n",
    "        self.device = torch.device(device)\n",
    "        self.model.to(self.device)\n",
    "        self.batch_augment_fn = batch_augment_fn\n",
    "\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        self.save_dir = save_dir\n",
    "        self.experiment_name = experiment_name\n",
    "\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.scaler = scaler\n",
    "\n",
    "        self.step_scheduler_per_batch = isinstance(scheduler, OneCycleLR)\n",
    "\n",
    "        self.best_f1 = 0.0\n",
    "        self.best_epoch = 0\n",
    "        self.history = {\n",
    "            'train_loss': [], 'val_loss': [],\n",
    "            'train_f1': [], 'val_f1': []\n",
    "        }\n",
    "\n",
    "        self.use_wandb = use_wandb\n",
    "        if use_wandb:\n",
    "            wandb.init(\n",
    "                project=experiment_name,\n",
    "                config={\n",
    "                    'num_epochs': num_epochs,\n",
    "                    'optimizer': str(optimizer),\n",
    "                    'device': device,\n",
    "                    'criterion': str(criterion),\n",
    "                    'scheduler': str(scheduler),\n",
    "                    'seed': seed\n",
    "                }\n",
    "            )\n",
    "\n",
    "        set_seed(seed)\n",
    "\n",
    "    def save_checkpoint(self, epoch: int, is_best: bool = False):\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'scheduler_state_dict': self.scheduler.state_dict() if self.scheduler else None,\n",
    "            'best_f1': self.best_f1,\n",
    "            'history': self.history\n",
    "        }\n",
    "\n",
    "        if is_best:\n",
    "            path = os.path.join(self.save_dir, f'{self.experiment_name}_best.pth')\n",
    "        else:\n",
    "            path = os.path.join(self.save_dir, f'{self.experiment_name}_epoch{epoch}.pth')\n",
    "\n",
    "        torch.save(checkpoint, path)\n",
    "\n",
    "    def train(self, start_epoch: int = 1):\n",
    "        for epoch in range(start_epoch, self.num_epochs + 1):\n",
    "            print(f\"\\nEpoch {epoch}/{self.num_epochs}\")\n",
    "\n",
    "            train_loss, train_f1 = training_epoch(\n",
    "                self.model, self.optimizer, self.criterion,\n",
    "                self.train_loader, self.device, f\"Train {epoch}\",\n",
    "                batch_augment_fn=self.batch_augment_fn,\n",
    "                scheduler=self.scheduler if self.step_scheduler_per_batch else None,\n",
    "                scaler=self.scaler if self.scaler else None,\n",
    "            )\n",
    "\n",
    "            val_loss, val_f1 = validation_epoch(\n",
    "                model=self.model,\n",
    "                criterion=self.criterion,\n",
    "                val_loader=self.val_loader,\n",
    "                device=self.device,\n",
    "                tqdm_desc=f\"Val {epoch}\",\n",
    "                teacher_model=None,\n",
    "                teacher_transform=None\n",
    "            )\n",
    "\n",
    "            if self.scheduler is not None and not self.step_scheduler_per_batch:\n",
    "                self.scheduler.step()\n",
    "\n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            self.history['val_loss'].append(val_loss)\n",
    "            self.history['train_f1'].append(train_f1)\n",
    "            self.history['val_f1'].append(val_f1)\n",
    "\n",
    "            metrics = {\n",
    "                'train/loss': train_loss,\n",
    "                'train/f1': train_f1,\n",
    "                'val/loss': val_loss,\n",
    "                'val/f1': val_f1,\n",
    "                'epoch': epoch\n",
    "            }\n",
    "\n",
    "            if self.scheduler:\n",
    "                metrics['lr'] = self.optimizer.param_groups[0]['lr']\n",
    "\n",
    "\n",
    "            if self.use_wandb:\n",
    "                wandb.log(metrics)\n",
    "\n",
    "            if val_f1 > self.best_f1:\n",
    "                self.best_f1 = val_f1\n",
    "                self.best_epoch = epoch\n",
    "                self.save_checkpoint(epoch, is_best=True)\n",
    "\n",
    "            self.save_checkpoint(epoch)\n",
    "\n",
    "            plot_losses(\n",
    "                self.history['train_loss'],\n",
    "                self.history['val_loss'],\n",
    "                self.history['train_f1'],\n",
    "                self.history['val_f1'],\n",
    "                clear=True\n",
    "            )\n",
    "\n",
    "        print(f\"Training completed. Best Val F1: {self.best_f1:.4f} at epoch {self.best_epoch}\")\n",
    "        return self.history"
   ],
   "id": "42f8ab53e4c7eb14",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Обучение",
   "id": "5e2dee4e793b4f44"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T13:27:19.739350Z",
     "start_time": "2025-04-12T13:27:19.736183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"✅ Using device: {device}\")"
   ],
   "id": "bbf337878bc93b60",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T13:27:37.306837Z",
     "start_time": "2025-04-12T13:27:19.758035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.models.teacher import ConvNeXtTeacher\n",
    "from src.utils import load_best_model\n",
    "from src.models.miniconvnext import MiniConvNeXt\n",
    "\n",
    "student_model = MiniConvNeXt(num_classes=16).to(device)\n",
    "student_model = student_model.to(device)\n",
    "\n",
    "teacher_model = ConvNeXtTeacher(num_classes=16)\n",
    "load_best_model(teacher_model, '../best_models/teacher.pth', device)\n",
    "teacher_model.eval().to(device)"
   ],
   "id": "4ae5d3245044bb3f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kira\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning:\n",
      "\n",
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "\n",
      "C:\\Users\\kira\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\timm\\models\\_factory.py:126: UserWarning:\n",
      "\n",
      "Mapping deprecated model name convnext_large_in22k to current convnext_large.fb_in22k.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded model weights from ../best_models/teacher.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConvNeXtTeacher(\n",
       "  (backbone): ConvNeXt(\n",
       "    (stem): Sequential(\n",
       "      (0): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (1): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "    (stages): Sequential(\n",
       "      (0): ConvNeXtStage(\n",
       "        (downsample): Identity()\n",
       "        (blocks): Sequential(\n",
       "          (0): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "            (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "            (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.006)\n",
       "          )\n",
       "          (2): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "            (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.011)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): ConvNeXtStage(\n",
       "        (downsample): Sequential(\n",
       "          (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.017)\n",
       "          )\n",
       "          (1): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.023)\n",
       "          )\n",
       "          (2): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.029)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): ConvNeXtStage(\n",
       "        (downsample): Sequential(\n",
       "          (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.034)\n",
       "          )\n",
       "          (1): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.040)\n",
       "          )\n",
       "          (2): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.046)\n",
       "          )\n",
       "          (3): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.051)\n",
       "          )\n",
       "          (4): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.057)\n",
       "          )\n",
       "          (5): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.063)\n",
       "          )\n",
       "          (6): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.069)\n",
       "          )\n",
       "          (7): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.074)\n",
       "          )\n",
       "          (8): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.080)\n",
       "          )\n",
       "          (9): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.086)\n",
       "          )\n",
       "          (10): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.091)\n",
       "          )\n",
       "          (11): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.097)\n",
       "          )\n",
       "          (12): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.103)\n",
       "          )\n",
       "          (13): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.109)\n",
       "          )\n",
       "          (14): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.114)\n",
       "          )\n",
       "          (15): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.120)\n",
       "          )\n",
       "          (16): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.126)\n",
       "          )\n",
       "          (17): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.131)\n",
       "          )\n",
       "          (18): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.137)\n",
       "          )\n",
       "          (19): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.143)\n",
       "          )\n",
       "          (20): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.149)\n",
       "          )\n",
       "          (21): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.154)\n",
       "          )\n",
       "          (22): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.160)\n",
       "          )\n",
       "          (23): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.166)\n",
       "          )\n",
       "          (24): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.171)\n",
       "          )\n",
       "          (25): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.177)\n",
       "          )\n",
       "          (26): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.183)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): ConvNeXtStage(\n",
       "        (downsample): Sequential(\n",
       "          (0): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (1): Conv2d(768, 1536, kernel_size=(2, 2), stride=(2, 2))\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
       "            (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.189)\n",
       "          )\n",
       "          (1): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
       "            (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.194)\n",
       "          )\n",
       "          (2): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
       "            (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): DropPath(drop_prob=0.200)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm_pre): Identity()\n",
       "    (head): NormMlpClassifierHead(\n",
       "      (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "      (norm): LayerNorm2d((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "      (pre_logits): Identity()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "      (fc): Identity()\n",
       "    )\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "    (1): Linear(in_features=1536, out_features=16, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-12T10:09:10.602357Z",
     "start_time": "2025-04-12T10:09:10.595762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.amp import GradScaler\n",
    "\n",
    "NUM_EPOCH = 45\n",
    "\n",
    "optimizer = torch.optim.AdamW(student_model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=3e-4,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    epochs=NUM_EPOCH,\n",
    "    pct_start=0.1,\n",
    "    anneal_strategy='cos',\n",
    "    div_factor=10.0,\n",
    "    final_div_factor=500\n",
    ")\n",
    "\n",
    "criterion = DistillationLoss(\n",
    "    teacher_model=teacher_model,\n",
    "    temperature=4.0,\n",
    "    alpha=0.7,\n",
    "    ce_smoothing=0.1\n",
    ")\n",
    "\n",
    "scaler = GradScaler()"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "augment_fn = distill_mixupcutmix_augment(\n",
    "    mixcut_fn = MixupCutMixAugmenter(alpha=0.5, p_mixup=0.3, p=0.5),\n",
    "    teacher_transform = val_transform\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=student_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=NUM_EPOCH,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scheduler=scheduler,\n",
    "    batch_augment_fn=augment_fn,\n",
    "    experiment_name=\"distillation_1\",\n",
    "    use_wandb=True,\n",
    "    seed=42,\n",
    "    scaler=scaler,\n",
    ")\n",
    "\n",
    "history = trainer.train()"
   ],
   "id": "c7d924538f5b748f",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T13:27:37.365539Z",
     "start_time": "2025-04-12T13:27:37.316097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.utils import load_best_model\n",
    "\n",
    "load_best_model(student_model, 'checkpoints/distillation_1_best.pth', device)"
   ],
   "id": "4ae6c933e06127d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded model weights from checkpoints/distillation_1_best.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MiniConvNeXt(\n",
       "  (downsample_layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (1): LayerNorm2d(\n",
       "        (norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): LayerNorm2d(\n",
       "        (norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "      (1): Conv2d(64, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): LayerNorm2d(\n",
       "        (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "      (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "  )\n",
       "  (stages): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): ConvNeXtBlock(\n",
       "        (dwconv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\n",
       "        (norm): LayerNorm2d(\n",
       "          (norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (pwconv1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): GELU(approximate='none')\n",
       "        (pwconv2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): ConvNeXtBlock(\n",
       "        (dwconv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\n",
       "        (norm): LayerNorm2d(\n",
       "          (norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (pwconv1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): GELU(approximate='none')\n",
       "        (pwconv2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ConvNeXtBlock(\n",
       "        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "        (norm): LayerNorm2d(\n",
       "          (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (pwconv1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): GELU(approximate='none')\n",
       "        (pwconv2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): ConvNeXtBlock(\n",
       "        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "        (norm): LayerNorm2d(\n",
       "          (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (pwconv1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): GELU(approximate='none')\n",
       "        (pwconv2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): ConvNeXtBlock(\n",
       "        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "        (norm): LayerNorm2d(\n",
       "          (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (pwconv1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): GELU(approximate='none')\n",
       "        (pwconv2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): ConvNeXtBlock(\n",
       "        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "        (norm): LayerNorm2d(\n",
       "          (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (pwconv1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): GELU(approximate='none')\n",
       "        (pwconv2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "  (head): Linear(in_features=256, out_features=16, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T13:27:37.377780Z",
     "start_time": "2025-04-12T13:27:37.373928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.amp import GradScaler\n",
    "\n",
    "NUM_EPOCH = 75\n",
    "\n",
    "optimizer = torch.optim.AdamW(student_model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=NUM_EPOCH,\n",
    "    eta_min=1e-6,\n",
    ")\n",
    "\n",
    "criterion = DistillationLoss(\n",
    "    teacher_model=teacher_model,\n",
    "    temperature=4.0,\n",
    "    alpha=0.7,\n",
    "    ce_smoothing=0.1\n",
    ")\n",
    "\n",
    "scaler = GradScaler()"
   ],
   "id": "90fd53552d5ae0d9",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "augment_fn = distill_mixupcutmix_augment(\n",
    "    mixcut_fn = MixupCutMixAugmenter(alpha=0.4, p_mixup=0.3, p=0.5),\n",
    "    teacher_transform = val_transform\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=student_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=NUM_EPOCH,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scheduler=scheduler,\n",
    "    batch_augment_fn=augment_fn,\n",
    "    experiment_name=\"distillation_1_2\",\n",
    "    use_wandb=True,\n",
    "    seed=42,\n",
    "    scaler=scaler,\n",
    ")\n",
    "\n",
    "history = trainer.train()"
   ],
   "id": "981a0c9c0f9caf0f",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T15:50:16.159397Z",
     "start_time": "2025-04-12T15:50:16.118673Z"
    }
   },
   "cell_type": "code",
   "source": "load_best_model(student_model, 'checkpoints/distillation_1_2_best.pth', device)",
   "id": "4309905e9c5f92fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded model weights from checkpoints/distillation_1_2_best.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MiniConvNeXt(\n",
       "  (downsample_layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (1): LayerNorm2d(\n",
       "        (norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): LayerNorm2d(\n",
       "        (norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "      (1): Conv2d(64, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): LayerNorm2d(\n",
       "        (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "      (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "  )\n",
       "  (stages): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): ConvNeXtBlock(\n",
       "        (dwconv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\n",
       "        (norm): LayerNorm2d(\n",
       "          (norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (pwconv1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): GELU(approximate='none')\n",
       "        (pwconv2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): ConvNeXtBlock(\n",
       "        (dwconv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\n",
       "        (norm): LayerNorm2d(\n",
       "          (norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (pwconv1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): GELU(approximate='none')\n",
       "        (pwconv2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ConvNeXtBlock(\n",
       "        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "        (norm): LayerNorm2d(\n",
       "          (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (pwconv1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): GELU(approximate='none')\n",
       "        (pwconv2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): ConvNeXtBlock(\n",
       "        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "        (norm): LayerNorm2d(\n",
       "          (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (pwconv1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): GELU(approximate='none')\n",
       "        (pwconv2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): ConvNeXtBlock(\n",
       "        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "        (norm): LayerNorm2d(\n",
       "          (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (pwconv1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): GELU(approximate='none')\n",
       "        (pwconv2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): ConvNeXtBlock(\n",
       "        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "        (norm): LayerNorm2d(\n",
       "          (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (pwconv1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): GELU(approximate='none')\n",
       "        (pwconv2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "  (head): Linear(in_features=256, out_features=16, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T15:50:16.853150Z",
     "start_time": "2025-04-12T15:50:16.847127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.amp import GradScaler\n",
    "\n",
    "NUM_EPOCH = 75\n",
    "\n",
    "optimizer = torch.optim.AdamW(student_model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=NUM_EPOCH,\n",
    "    eta_min=1e-7,\n",
    ")\n",
    "\n",
    "criterion = DistillationLoss(\n",
    "    teacher_model=teacher_model,\n",
    "    temperature=4.0,\n",
    "    alpha=0.7,\n",
    "    ce_smoothing=0.1\n",
    ")\n",
    "\n",
    "scaler = GradScaler()"
   ],
   "id": "7df3a2349124d879",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "augment_fn = distill_mixupcutmix_augment(\n",
    "    mixcut_fn = MixupCutMixAugmenter(alpha=0.5, p_mixup=0.3, p=0.75),\n",
    "    teacher_transform = val_transform\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=student_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=NUM_EPOCH,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scheduler=scheduler,\n",
    "    batch_augment_fn=augment_fn,\n",
    "    experiment_name=\"distillation_1_3\",\n",
    "    use_wandb=True,\n",
    "    seed=42,\n",
    "    scaler=scaler,\n",
    ")\n",
    "\n",
    "history = trainer.train()"
   ],
   "id": "378cc652a56cd794",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 75: 100%|██████████| 310/310 [00:44<00:00,  6.93it/s]\n",
      "Val 75:  68%|██████▊   | 53/78 [00:15<00:07,  3.32it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 22\u001B[0m\n\u001B[0;32m      1\u001B[0m augment_fn \u001B[38;5;241m=\u001B[39m distill_mixupcutmix_augment(\n\u001B[0;32m      2\u001B[0m     mixcut_fn \u001B[38;5;241m=\u001B[39m MixupCutMixAugmenter(alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m, p_mixup\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.3\u001B[39m, p\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.75\u001B[39m),\n\u001B[0;32m      3\u001B[0m     teacher_transform \u001B[38;5;241m=\u001B[39m val_transform\n\u001B[0;32m      4\u001B[0m )\n\u001B[0;32m      7\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\n\u001B[0;32m      8\u001B[0m     model\u001B[38;5;241m=\u001B[39mstudent_model,\n\u001B[0;32m      9\u001B[0m     train_loader\u001B[38;5;241m=\u001B[39mtrain_loader,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     19\u001B[0m     scaler\u001B[38;5;241m=\u001B[39mscaler,\n\u001B[0;32m     20\u001B[0m )\n\u001B[1;32m---> 22\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[8], line 97\u001B[0m, in \u001B[0;36mTrainer.train\u001B[1;34m(self, start_epoch)\u001B[0m\n\u001B[0;32m     87\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_epochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     89\u001B[0m train_loss, train_f1 \u001B[38;5;241m=\u001B[39m training_epoch(\n\u001B[0;32m     90\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcriterion,\n\u001B[0;32m     91\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_loader, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTrain \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     94\u001B[0m     scaler\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscaler \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscaler \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m     95\u001B[0m )\n\u001B[1;32m---> 97\u001B[0m val_loss, val_f1 \u001B[38;5;241m=\u001B[39m \u001B[43mvalidation_epoch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     98\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     99\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    100\u001B[0m \u001B[43m    \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    101\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    102\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtqdm_desc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mVal \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mepoch\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    103\u001B[0m \u001B[43m    \u001B[49m\u001B[43mteacher_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    104\u001B[0m \u001B[43m    \u001B[49m\u001B[43mteacher_transform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\n\u001B[0;32m    105\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    107\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscheduler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstep_scheduler_per_batch:\n\u001B[0;32m    108\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscheduler\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    115\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[1;32m--> 116\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[7], line 97\u001B[0m, in \u001B[0;36mvalidation_epoch\u001B[1;34m(model, criterion, val_loader, device, tqdm_desc, teacher_model, teacher_transform)\u001B[0m\n\u001B[0;32m     94\u001B[0m     logits \u001B[38;5;241m=\u001B[39m model(images)\n\u001B[0;32m     95\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(logits, labels)\n\u001B[1;32m---> 97\u001B[0m val_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m*\u001B[39m images\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     98\u001B[0m all_preds\u001B[38;5;241m.\u001B[39mappend(logits\u001B[38;5;241m.\u001B[39margmax(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mcpu())\n\u001B[0;32m     99\u001B[0m all_labels\u001B[38;5;241m.\u001B[39mappend(labels\u001B[38;5;241m.\u001B[39mcpu())\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "905a1ba40f5eaaec"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
