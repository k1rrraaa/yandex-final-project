{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.models.miniconvnext import MiniConvNeXt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from src.trainer import Trainer\n",
    "from src.dataset import HumanPosesDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.transforms as T\n",
    "import torch"
   ],
   "id": "576af41bbf05318c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = \"browser\" "
   ],
   "id": "301f9e514b69841",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Сначала посчитаю mean и std\n",
   "id": "d176f05815ba10f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "CSV_PATH = Path(\"../data/human_poses_data/train_answers.csv\")\n",
    "TRAIN_DIR = Path(\"../data/human_poses_data/img_train\")\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "train_ids, val_ids = train_test_split(\n",
    "    df['img_id'].values,\n",
    "    test_size=0.2,\n",
    "    stratify=df['target_feature'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_df = df[df['img_id'].isin(train_ids)]\n",
    "val_df = df[df['img_id'].isin(val_ids)]"
   ],
   "id": "61e07c3f6f89b1c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "transform_for_stats = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset_raw = HumanPosesDataset(\n",
    "    root_dir=TRAIN_DIR.parent,\n",
    "    mode='train',\n",
    "    transform=transform_for_stats\n",
    ")\n",
    "\n",
    "train_idx = train_df.index.tolist()\n",
    "train_dataset_raw = Subset(train_dataset_raw, train_idx[:256])\n",
    "\n",
    "train_loader_raw = DataLoader(\n",
    "    train_dataset_raw,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n"
   ],
   "id": "51dfec031ebd90d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compute_mean_std(loader):\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    nb_samples = 0.\n",
    "\n",
    "    for data, _ in tqdm(loader, desc=\"Computing mean/std\"):\n",
    "        batch_samples = data.size(0)\n",
    "        data = data.view(batch_samples, data.size(1), -1)\n",
    "        mean += data.mean(2).sum(0)\n",
    "        std += data.std(2).sum(0)\n",
    "        nb_samples += batch_samples\n",
    "\n",
    "    mean /= nb_samples\n",
    "    std /= nb_samples\n",
    "    return mean, std\n",
    "\n",
    "mean, std = compute_mean_std(train_loader_raw)\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Std:\", std)"
   ],
   "id": "4a53b990fa25ce62",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "49c79ce6008da18d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "mean = [0.4638, 0.4522, 0.4148]\n",
    "std = [0.2222, 0.2198, 0.2176]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=224, scale=(0.7, 1.0), ratio=(0.75, 1.33)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2)\n",
    "    ], p=0.3),\n",
    "    transforms.RandomGrayscale(p=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n"
   ],
   "id": "2792677228205728",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "CSV_PATH = Path(\"../data/human_poses_data/train_answers.csv\")\n",
    "TRAIN_DIR = Path(\"../data/human_poses_data/img_train\")\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "train_ids, val_ids = train_test_split(\n",
    "    df['img_id'].values,\n",
    "    test_size=0.2,\n",
    "    stratify=df['target_feature'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_df = df[df['img_id'].isin(train_ids)].reset_index(drop=True)\n",
    "val_df = df[df['img_id'].isin(val_ids)].reset_index(drop=True)\n",
    "\n",
    "train_dataset = HumanPosesDataset(\n",
    "    data_df=train_df,\n",
    "    img_dir=TRAIN_DIR,\n",
    "    transform=train_transform,\n",
    "    preload=True\n",
    ")\n",
    "\n",
    "val_dataset = HumanPosesDataset(\n",
    "    data_df=val_df,\n",
    "    img_dir=TRAIN_DIR,\n",
    "    transform=val_transform,\n",
    "    preload=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")"
   ],
   "id": "aca617e9abc3b4fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_classes = len(np.unique(df['target_feature'])) \n",
    "print(f\"Количество классов: {num_classes}\")"
   ],
   "id": "b89ebb40f0a93eab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Обучение",
   "id": "3728f438e13f4dd7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model = MiniConvNeXt(num_classes=num_classes)",
   "id": "238c52e9fccf5c27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "NUM_EPOCH = 25\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCH)\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ],
   "id": "c646d50ca69469b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=NUM_EPOCH,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    device = device,\n",
    "    criterion=criterion,\n",
    "    experiment_name=\"miniconvnext\",\n",
    "    use_wandb=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "history = trainer.train()"
   ],
   "id": "ac856eeba3b71c98",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.utils import load_best_model\n",
    "\n",
    "model = load_best_model(model, \"checkpoints/miniconvnext_epoch16.pth\", device=device)"
   ],
   "id": "aaf463f1cc56fb3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=15)\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=15,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    device = device,\n",
    "    criterion=criterion,\n",
    "    experiment_name=\"miniconvnext_2\",\n",
    "    use_wandb=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "history = trainer.train()"
   ],
   "id": "201012bbcbe7b4cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "он переобучается, нужны более сильные аугментации",
   "id": "a018da4e441f952f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
