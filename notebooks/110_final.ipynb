{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from src.dataset import HumanPosesDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch"
   ],
   "id": "d0d4534c9405f683",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# –ê–Ω—Å–∞–º–±–ª—å",
   "id": "966299953c0830e7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## –î–∞—Ç–∞—Å–µ—Ç –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏",
   "id": "f0e4aaae609d68cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "mean = [0.4638, 0.4522, 0.4148]\n",
    "std = [0.2222, 0.2198, 0.2176]\n",
    "\n",
    "tta_transforms = [\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ]),\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.RandomHorizontalFlip(p=1.0),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ]),\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(p=1.0),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ]),\n",
    "]"
   ],
   "id": "f9d998e2e458e33e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "CSV_PATH = Path(\"../data/human_poses_data/train_answers.csv\")\n",
    "TRAIN_DIR = Path(\"../data/human_poses_data/img_train\")\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "train_ids, val_ids = train_test_split(\n",
    "    df['img_id'].values,\n",
    "    test_size=0.2,\n",
    "    stratify=df['target_feature'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "val_df = df[df['img_id'].isin(val_ids)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "val_dataset = HumanPosesDataset(\n",
    "    data_df=val_df,\n",
    "    img_dir=TRAIN_DIR,\n",
    "    transform=None, #—Ç–æ–ª—å–∫–æ –≤ —ç—Ç–æ–º –Ω–æ—É—Ç–±—É–∫–µ\n",
    ")\n",
    "\n",
    "def pil_collate(batch):\n",
    "    images, labels = zip(*batch)\n",
    "    return list(images), list(labels)\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=pil_collate,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")"
   ],
   "id": "171008d9e81ec16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"‚úÖ Using device: {device}\")"
   ],
   "id": "3effcf5c50081390",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π –∏ –≤–µ—Å–æ–≤",
   "id": "7cc0ec9b334a26c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.models.tinyvit import TinyViT\n",
    "from src.models.enet import EfficientNetV2\n",
    "from src.models.convnextv2 import ConvNeXtV2\n",
    "from src.models.miniconvnext import MiniConvNeXt\n",
    "from src.utils import load_best_model\n",
    "\n",
    "num_classes = 16\n",
    "\n",
    "tiny_vit_ssl = TinyViT(in_chans=3, num_classes=num_classes, model_size='11M').to(device)\n",
    "load_best_model(tiny_vit_ssl, '../best_models/ssl_vit_1_5_best.pth', device)\n",
    "\n",
    "tiny_vit_no_ssl = TinyViT(in_chans=3, model_size='11M', num_classes=num_classes).to(device)\n",
    "load_best_model(tiny_vit_no_ssl, '../best_models/my_vit_4_best.pth', device)\n",
    "\n",
    "enet_v2_m = EfficientNetV2(variant='M', num_classes=num_classes).to(device)\n",
    "load_best_model(enet_v2_m, '../best_models/enet_1_5_best.pth', device)\n",
    "\n",
    "convnextv2_small = ConvNeXtV2(num_classes=num_classes, variant='small').to(device)\n",
    "load_best_model(convnextv2_small, '../best_models/convnextv2_small_3_best.pth', device)\n",
    "\n",
    "convnextv2_base = ConvNeXtV2(num_classes=num_classes, variant='base').to(device)\n",
    "load_best_model(convnextv2_base, '../best_models/convnextv2_base_3_best.pth', device)\n",
    "\n",
    "miniconvnext = MiniConvNeXt(num_classes=num_classes).to(device)\n",
    "load_best_model(miniconvnext, '../best_models/convnext_last.pth', device)"
   ],
   "id": "b6c5f8c6cce9f423",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def validate_all_models(models, val_loader, tta_transforms, true_labels, device):\n",
    "    from src.ensemble import WeightedEnsemble\n",
    "\n",
    "    scores = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nüîç Validating model: {name}\")\n",
    "\n",
    "        ensemble = WeightedEnsemble({name: 1.0})\n",
    "        predictions, _ = ensemble.predict_from_models(\n",
    "            models={name: model},\n",
    "            dataloader=val_loader,\n",
    "            device=device,\n",
    "            tta_transforms=tta_transforms\n",
    "        )\n",
    "        f1 = ensemble.validate(predictions, true_labels)\n",
    "        scores[name] = f1\n",
    "\n",
    "    print(\"\\nAll F1-scores:\")\n",
    "    for name, score in scores.items():\n",
    "        print(f\"{name}: {score:.4f}\")\n",
    "\n",
    "    return scores"
   ],
   "id": "6a56528672317c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "models = {\n",
    "    \"tiny_vit_ssl\": tiny_vit_ssl,\n",
    "    \"tiny_vit_no_ssl\": tiny_vit_no_ssl,\n",
    "    \"enet_v2_m\": enet_v2_m,\n",
    "    \"convnextv2_small\": convnextv2_small,\n",
    "    \"convnextv2_base\": convnextv2_base,\n",
    "    \"miniconvnext\": miniconvnext\n",
    "}\n",
    "\n",
    "true_labels = list(val_dataset.labels)\n",
    "\n",
    "validate_all_models(models, val_loader, tta_transforms, true_labels, device)"
   ],
   "id": "bdbd914018cbc336",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "F1-scores: <br>\n",
    "tiny_vit_ssl: 0.7252 <br>\n",
    "tiny_vit_no_ssl: 0.7207 <br>\n",
    "enet_v2_m: 0.7147 <br>\n",
    "convnextv2_small: 0.7188 <br>\n",
    "convnextv2_base: 0.6958 <br>\n",
    "miniconvnext: 0.6969 <br>"
   ],
   "id": "d7cdfb67f7bdef17"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Optuna",
   "id": "5986316747858235"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.ensemble import WeightedEnsemble\n",
    "\n",
    "ensemble = WeightedEnsemble({name: 1.0 for name in models})\n",
    "predictions, _ = ensemble.predict_from_models(\n",
    "    models=models,\n",
    "    dataloader=val_loader,\n",
    "    device=device,\n",
    "    tta_transforms=tta_transforms\n",
    ")"
   ],
   "id": "7ec8d2f287269a59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "np.savez(\"val_logits.npz\", **predictions)\n",
    "true_labels = list(val_dataset.labels)\n",
    "np.save(\"true_labels.npy\", true_labels)"
   ],
   "id": "55ecc59ce4de1452",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "logits_data = np.load(\"val_logits.npz\")\n",
    "\n",
    "logits_dict = {k: v for k, v in logits_data.items()}\n",
    "model_names = list(logits_dict.keys())\n",
    "\n",
    "true_labels = np.load(\"true_labels.npy\")\n",
    "\n",
    "num_classes = next(iter(logits_dict.values())).shape[1]\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    weights = np.array([trial.suggest_float(name, 0.0, 1.0) for name in model_names])\n",
    "    weights /= weights.sum() + 1e-8\n",
    "\n",
    "    logits = sum(w * logits_dict[name] for w, name in zip(weights, model_names))\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    return f1_score(true_labels, preds, average=\"macro\")\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "study.best_params, study.best_value"
   ],
   "id": "387a143f72add4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.ensemble import WeightedEnsemble\n",
    "\n",
    "ensemble = WeightedEnsemble({\n",
    "    'tiny_vit_ssl': 0.18659441736954463,\n",
    "    'tiny_vit_no_ssl': 0.24930515606163378,\n",
    "    'enet_v2_m': 0.32824274496866923,\n",
    "    'convnextv2_small': 0.4704414186510291,\n",
    "    'convnextv2_base': 0.185445131248959,\n",
    "    'miniconvnext': 0.38462473460682\n",
    "})\n",
    "\n",
    "models = {\"tiny_vit_no_ssl\": tiny_vit_no_ssl,\n",
    "          \"tiny_vit_ssl\": tiny_vit_ssl,\n",
    "          'enet_v2_m': enet_v2_m,\n",
    "          'convnextv2_small': convnextv2_small,\n",
    "          'convnextv2_base': convnextv2_base,\n",
    "          'miniconvnext': miniconvnext}"
   ],
   "id": "47315a07956be377",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## –í–∞–ª–∏–¥–∞—Ü–∏—è",
   "id": "fae45d137faf31e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "true_labels = val_dataset.labels.tolist()\n",
    "\n",
    "predictions, _ = ensemble.predict_from_models(\n",
    "    models=models,\n",
    "    dataloader=val_loader,\n",
    "    device=device,\n",
    "    tta_transforms=tta_transforms\n",
    ")\n",
    "\n",
    "ensemble.validate(predictions, true_labels)"
   ],
   "id": "dbc8692df984628e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## –°–∞–±–º–∏—Ç",
   "id": "3c29257ec5d77782"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.ensemble import TestDataset\n",
    "\n",
    "TEST_DIR = Path(\"../data/human_poses_data/img_test\")\n",
    "\n",
    "test_image_paths = list(TEST_DIR.glob(\"*.jpg\"))\n",
    "\n",
    "test_ids = [int(p.stem) for p in test_image_paths]\n",
    "\n",
    "test_dataset = TestDataset(test_image_paths, test_ids)\n",
    "\n",
    "def pil_collate(batch):\n",
    "    images, ids = zip(*batch)\n",
    "    return list(images), list(ids)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=pil_collate,\n",
    "    pin_memory=True\n",
    ")"
   ],
   "id": "2588081c284d2f30",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "predictions, image_ids = ensemble.predict_from_models(\n",
    "    models=models,\n",
    "    dataloader=test_loader,\n",
    "    device=device,\n",
    "    tta_transforms=tta_transforms\n",
    ")\n",
    "\n",
    "ensemble.make_submission(\n",
    "    predictions=predictions,\n",
    "    image_ids=image_ids,\n",
    "    index_to_class=val_dataset.index_to_class,\n",
    "    output_path=\"submission.csv\"\n",
    ")"
   ],
   "id": "5bdf232ec370c941",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# –°—Ç–µ–∫–∏–Ω–≥",
   "id": "3d144493f295899c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from scipy.special import softmax\n",
    "\n",
    "logits_dict = np.load(\"val_logits.npz\")\n",
    "y = np.load(\"true_labels.npy\")\n",
    "\n",
    "X_raw = np.concatenate([logits_dict[k] for k in logits_dict], axis=1)\n",
    "\n",
    "def meta_features(logits):\n",
    "    probs = softmax(logits, axis=1)\n",
    "    entropy = -np.sum(probs * np.log(probs + 1e-8), axis=1, keepdims=True)\n",
    "    confidence = np.max(probs, axis=1, keepdims=True)\n",
    "    sorted_probs = -np.sort(-probs, axis=1)\n",
    "    margin = (sorted_probs[:, 0] - sorted_probs[:, 1]).reshape(-1, 1)\n",
    "    return np.concatenate([entropy, confidence, margin], axis=1)\n",
    "\n",
    "meta_feats = np.concatenate([meta_features(logits_dict[k]) for k in logits_dict], axis=1)\n",
    "X = np.concatenate([X_raw, meta_feats], axis=1)\n",
    "\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "oof_preds_cat = np.zeros((len(y), num_classes))\n",
    "oof_preds_lgb = np.zeros((len(y), num_classes))\n",
    "\n",
    "for train_idx, val_idx in skf.split(X, y):\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_val = X[val_idx]\n",
    "\n",
    "    cat = CatBoostClassifier(iterations=500, learning_rate=0.05, depth=4, l2_leaf_reg=10,\n",
    "                             early_stopping_rounds=20, verbose=False)\n",
    "    lgb = LGBMClassifier(n_estimators=500, learning_rate=0.05, max_depth=4, reg_lambda=10)\n",
    "\n",
    "    cat.fit(X_train, y_train)\n",
    "    lgb.fit(X_train, y_train)\n",
    "\n",
    "    oof_preds_cat[val_idx] = cat.predict_proba(X_val)\n",
    "    oof_preds_lgb[val_idx] = lgb.predict_proba(X_val)\n",
    "\n",
    "optuna_weights = {\n",
    "    'tiny_vit_ssl': 0.18659441736594463,\n",
    "    'tiny_vit_no_ssl': 0.24903515606163378,\n",
    "    'enet_v2_m': 0.3282474648666293,\n",
    "    'convnextv2_small': 0.4790441486510921,\n",
    "    'convnextv2_base': 0.185445312408959,\n",
    "    'miniconvnext': 0.38462473466082\n",
    "}\n",
    "\n",
    "norm = sum(optuna_weights.values())\n",
    "optuna_weights = {k: v / norm for k, v in optuna_weights.items()}\n",
    "\n",
    "oof_preds_opt = np.zeros_like(oof_preds_cat)\n",
    "for name, weight in optuna_weights.items():\n",
    "    oof_preds_opt += weight * logits_dict[name]\n",
    "\n",
    "oof_blend = 0.4 * oof_preds_cat + 0.3 * oof_preds_lgb + 0.3 * oof_preds_opt\n",
    "oof_pred_labels = np.argmax(oof_blend, axis=1)\n",
    "f1 = f1_score(y, oof_pred_labels, average=\"macro\")\n",
    "print(f\"\\nFINAL OOF F1: {f1:.5f}\")"
   ],
   "id": "1edd5c58e156c398",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cat_final = CatBoostClassifier(iterations=500, learning_rate=0.05, depth=4, l2_leaf_reg=10,\n",
    "                               early_stopping_rounds=20, verbose=False)\n",
    "lgb_final = LGBMClassifier(n_estimators=500, learning_rate=0.05, max_depth=4, reg_lambda=10)\n",
    "cat_final.fit(X, y)\n",
    "lgb_final.fit(X, y)"
   ],
   "id": "9d420d2531322e2a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_logits = np.load(\"test_logits.npz\")\n",
    "test_ids = np.load(\"test_ids.npy\")\n",
    "X_test_raw = np.concatenate([test_logits[k] for k in test_logits], axis=1)\n",
    "meta_feats_test = np.concatenate([meta_features(test_logits[k]) for k in test_logits], axis=1)\n",
    "X_test = np.concatenate([X_test_raw, meta_feats_test], axis=1)\n",
    "\n",
    "test_preds_opt = np.zeros((len(test_ids), num_classes))\n",
    "for name, weight in optuna_weights.items():\n",
    "    test_preds_opt += weight * test_logits[name]\n",
    "\n",
    "cat_probs = cat_final.predict_proba(X_test)\n",
    "lgb_probs = lgb_final.predict_proba(X_test)\n",
    "final_probs = 0.4 * cat_probs + 0.3 * lgb_probs + 0.3 * test_preds_opt\n",
    "y_pred = np.argmax(final_probs, axis=1)\n",
    "\n",
    "index_to_class = val_dataset.index_to_class\n",
    "decoded_preds = [index_to_class[int(p)] for p in y_pred]\n",
    "submission = pd.DataFrame({\"id\": test_ids, \"target_feature\": decoded_preds})\n",
    "submission = submission.sort_values(\"id\")\n",
    "submission.to_csv(\"final_sota_optuna_cat_lgb_submission.csv\", index=False)\n",
    "print(\"FINAL SUBMISSION SAVED: final.csv\")"
   ],
   "id": "a6bae95a062ef066",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
